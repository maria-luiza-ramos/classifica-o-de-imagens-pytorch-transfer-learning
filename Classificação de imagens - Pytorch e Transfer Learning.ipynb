{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dc574ee",
   "metadata": {},
   "source": [
    "## Projeto 6 - Classificação de imagens - Pytorch e Transfer Learning\n",
    "\n",
    "        Let's Data - Jornada Cientista da Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb28ef12",
   "metadata": {},
   "source": [
    "**Motivação:** Estudar sobre utilização de redes pré-treinadas na classificação de imagens \n",
    "\n",
    "**Objeto de Estudo:** Na empresa fictícia Let's Veggie está com um problema na classificação dos produtos na loja. Muitos funcionarios não sabem diferenciar os vegetais e frutas, assim a empresa precisa de uma aplicação que faça essa classificação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec348e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch torchvision pillow scikit-learn gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e21041e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando as bibliotecas \n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np \n",
    "import os \n",
    "import PIL.Image #usamos para mostrar as imagens e ler elas \n",
    "\n",
    "import time \n",
    "import torch, torchvision \n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader # estrutura os dados para rede de treinamento \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c759235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['batata', 'cenoura', 'limao', 'tomate']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separando as imagens em base de treino, validação e teste. Importante deixar uma pasta raw com os dados originais \n",
    "\n",
    "diretorio_base_imagens = \"C:\\\\Users\\\\maria\\\\Projeto 6\\\\data\\\\raw\"\n",
    "\n",
    "# 'os.listdir' - Retorna uma lista contendo os nomes dos arquivos no diretório.\n",
    "pasta_com_os_nomes_de_vegetais = os.listdir(diretorio_base_imagens)\n",
    "pasta_com_os_nomes_de_vegetais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23e32a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batata': 146, 'cenoura': 181, 'limao': 111, 'tomate': 107}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separando a basa em 80% treino, 10% validação, 10% teste. Vamos criar uma separação estratificada \n",
    "\n",
    "quantidade_por_label = {}\n",
    "for pasta in pasta_com_os_nomes_de_vegetais:\n",
    "    # 'os.path.join' - une um ou mais componentes de caminho de forma inteligente.\n",
    "    # '(os.listdir(os.path.join(diretorio_base_imagens,pasta)' - lista todas as imagens que tem dentro da pasta \n",
    "    quantidade_por_label[pasta] = len(os.listdir(os.path.join(diretorio_base_imagens,pasta)))\n",
    "\n",
    "quantidade_por_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12f729db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando uma pasta de treino, validação e teste\n",
    "\n",
    "diretorio_imagens_processadas = \"C:\\\\Users\\\\maria\\\\Projeto 6\\\\data\\\\processed\"\n",
    "\n",
    "dir_treino = os.path.join(diretorio_imagens_processadas, 'treino')\n",
    "dir_validacao = os.path.join(diretorio_imagens_processadas, 'validacao')\n",
    "dir_teste = os.path.join(diretorio_imagens_processadas, 'teste')\n",
    "\n",
    "#verificando se as pastas foram criadas, senão foram 'os.makedirs' cria \n",
    "\n",
    "if not os.path.exists(dir_treino):\n",
    "    os.makedirs(dir_treino)\n",
    "\n",
    "if not os.path.exists(dir_validacao):\n",
    "    os.makedirs(dir_validacao)\n",
    "    \n",
    "if not os.path.exists(dir_teste):\n",
    "    os.makedirs(dir_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74a6ea67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando a biblioteca shutil para fazer copia de arquivo \n",
    "\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a18fe05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batata - treino: 116 - validação: 15 - teste: 15\n",
      "cenoura - treino: 144 - validação: 18 - teste: 19\n",
      "limao - treino: 88 - validação: 11 - teste: 12\n",
      "tomate - treino: 85 - validação: 11 - teste: 11\n"
     ]
    }
   ],
   "source": [
    "# Criando uma pasta para cada classe(batata, cenoura, limao, tomate) dentro de treino, validação e teste \n",
    "\n",
    "for classe in pasta_com_os_nomes_de_vegetais:\n",
    "    \n",
    "    dir_classe_treino = os.path.join(dir_treino, classe)\n",
    "    dir_classe_validacao = os.path.join(dir_validacao, classe)\n",
    "    dir_classe_teste = os.path.join(dir_teste, classe)\n",
    "    \n",
    "    if not os.path.exists(dir_classe_treino):\n",
    "        os.makedirs(dir_classe_treino)\n",
    "        \n",
    "    if not os.path.exists(dir_classe_validacao):\n",
    "        os.makedirs(dir_classe_validacao)\n",
    "        \n",
    "    if not os.path.exists(dir_classe_teste):\n",
    "        os.makedirs(dir_classe_teste)\n",
    "        \n",
    "    # fazendo o caminho para a pasta com as imagens originais \n",
    "    pasta_classe = os.path.join(diretorio_base_imagens, classe)\n",
    "    \n",
    "    # listando todos os arquivos de imagem para essa clase \n",
    "    arquivos_classe = os.listdir(pasta_classe)\n",
    "    \n",
    "    # separando 80% treino e 20% validação/teste - Fazendo a separação em 80/20 pois 'train_test_split' separa apenas 2 \n",
    "    # estamos passando uma lista com as imagens de cada classe, 'shuffle=True' ele vai embaralrar as imagens \n",
    "    treino, valid_test = train_test_split(arquivos_classe, shuffle=True, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Fazendo o 2 split no 'valid_test'. Agora o 'test_size' coloco 0.5 para divir em 50%\n",
    "    validacao, teste = train_test_split(valid_test,shuffle=True,test_size=0.5,random_state=42)\n",
    "    \n",
    "    # Agora que tenho as variáveis de validação e teste não preciso mais da valid_test\n",
    "    del valid_test\n",
    "    \n",
    "    print(f'{classe} - treino: {len(treino)} - validação: {len(validacao)} - teste: {len(teste)}')\n",
    "    \n",
    "    # Copiando os arquivos efetivamente para as pastas de treino, validação e teste \n",
    "    for imagem_treino in treino:\n",
    "        caminho_origem = os.path.join(diretorio_base_imagens, classe, imagem_treino)\n",
    "        caminho_destino = os.path.join(dir_classe_treino, imagem_treino)\n",
    "        # estou pegando imagem por imagem caminho_origem (raw-'batata/tomante...'-imagem) e fazendo uma copia no \n",
    "        # caminho_destino (processed-treino-'batata/tomate...'-imagem)\n",
    "        shutil.copy(caminho_origem, caminho_destino)\n",
    "    \n",
    "    \n",
    "    for imagem_validacao in validacao:\n",
    "        caminho_origem = os.path.join(diretorio_base_imagens, classe, imagem_validacao)\n",
    "        caminho_destino = os.path.join(dir_classe_validacao, imagem_validacao)\n",
    "       \n",
    "        shutil.copy(caminho_origem, caminho_destino)\n",
    "        \n",
    "    \n",
    "    for imagem_teste in teste:\n",
    "        caminho_origem = os.path.join(diretorio_base_imagens, classe, imagem_teste)\n",
    "        caminho_destino = os.path.join(dir_classe_teste, imagem_teste)\n",
    "       \n",
    "        shutil.copy(caminho_origem, caminho_destino)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3abe2a8",
   "metadata": {},
   "source": [
    "### Pré Processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e19b97a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definido o tamanho da imagem para 100\n",
    "imagem_size = 100 \n",
    "\n",
    "# 'transforms' - transformando as imagens \n",
    "transformacao_de_imagem = {\n",
    "    'treino': transforms.Compose([ # Compõe várias transformações juntas.\n",
    "        transforms.Resize(size=[imagem_size, imagem_size]), # Redimensiona a imagem de entrada em tamanho especificado.100p/100\n",
    "        transforms.ToTensor() # Converter um ``PIL Image`` ou ``numpy.ndarray`` para tensor.\n",
    "     ]), \n",
    "    'validacao': transforms.Compose([\n",
    "        transforms.Resize(size=[imagem_size,imagem_size]),\n",
    "        transforms.ToTensor()\n",
    "    ]),\n",
    "    'teste': transforms.Compose([\n",
    "        transforms.Resize(size=[imagem_size,imagem_size]),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8a3132",
   "metadata": {},
   "source": [
    "Nessa transformação fizemos o redimensionamento das imagens e passamos para tensores Py Torch. Como não foi uma alteração significativa as mudanças vão ser feitas mas imagens de treinamento, validação e teste \n",
    "\n",
    "Caso tenha a necessidade de fazer mais alterações vamos fazer apenas no treino. Podemos fazer rotações, espelhamentos, crop randomicos... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16bea18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renomeando os nomes das pastas \n",
    "\n",
    "pasta_treino = dir_treino\n",
    "pasta_validacao = dir_validacao\n",
    "pasta_teste = dir_teste"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cc8b10",
   "metadata": {},
   "source": [
    "**Preparação para o treinamento**\n",
    "\n",
    "    Definido informações importantes para o modelo - Tamanho do batch, número de classes, datasets, dataloaders(organiza os dados para treinamento e validação para o treinamento da rede neural), otimizadores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f80ae925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tamanho do batch (vamos treinar de 8 em 8 imagens)\n",
    "tamanho_do_batch = 8 \n",
    "\n",
    "#número de classes \n",
    "numero_classes = len(os.listdir(pasta_treino)) # vamos usar o len caso depois adicionarmos outra classe a variável atualiza "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e22f80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# carregando as imagens usando o datasets do torchvision \n",
    "\n",
    "# 'ImageFolder' - Um carregador de dados genérico onde as imagens são organizadas dessa maneira por padrão\n",
    "    # root= Caminho do diretório raiz\n",
    "    # transform= Falo quais são as transfgormações que eu quero que sejam feitas \n",
    "data = {\n",
    "    'treino': datasets.ImageFolder(root=pasta_treino, transform=transformacao_de_imagem['treino']),\n",
    "    'validacao': datasets.ImageFolder(root=pasta_validacao, transform=transformacao_de_imagem['validacao'])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c2083e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'batata', 1: 'cenoura', 2: 'limao', 3: 'tomate'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# associando os indices com os nomes das classes \n",
    "\n",
    "# estamos fazendo um dict comprehension, onde o indice é a chave e o nome da classe é o valor \n",
    "indice_para_classes = {indice: classes for classes, indice in data['treino'].class_to_idx.items()}\n",
    "\n",
    "indice_para_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb0fa296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(433, 55)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quantidade de imagens para serem usadas para calcular o erro médio e a acurácia \n",
    "\n",
    "num_imagens_treino = len(data['treino'])\n",
    "num_imagens_validacao = len(data['validacao'])\n",
    "\n",
    "num_imagens_treino, num_imagens_validacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d51a5515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando os DataLoader para o treino e validação \n",
    "\n",
    "data_loader_treino = DataLoader(data['treino'], batch_size=tamanho_do_batch,shuffle=True)\n",
    "data_loader_validacao = DataLoader(data['validacao'], batch_size=tamanho_do_batch,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77181b8",
   "metadata": {},
   "source": [
    "### Transfer Learning \n",
    "\n",
    "Temos poucas imagens, dessa maneira fica dificil treinar um modelo de maneira eficiente. Assim vamos usar a Alexnet que tem milhares de imagem treinandas para ajudar nosso modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "404e0f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carregando Alexnet\n",
    "# \"weights=models.AlexNet_Weights.DEFAULT\" falo que quero as imagens pré treinadas \n",
    "\n",
    "alexnet = models.alexnet(weights=models.AlexNet_Weights.DEFAULT)\n",
    "\n",
    "alexnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8610ba7",
   "metadata": {},
   "source": [
    "Precisamos congelar os parametros da rede pré treinada, pois vou mudar a ultima camada para ele aprender as imagens que tenho salva, mas não quero que ele reaprenda todas as imgens que alexnet tem.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17e261dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precisamos congelar os parametros da rede pré-treinada \n",
    "\n",
    "for param in alexnet.parameters():\n",
    "    # 'requires_grade' - desliga o treinamento e atualização dos pesos (coeficientes) das camadas da rede neural \n",
    "    param.requires_grade=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d2a28a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=4, bias=True)\n",
       "    (7): LogSoftmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alterando a ultima camada. Era - (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
    "# e vai ficar (6): Linear(in_features=4096, out_features=4, bias=True) \n",
    "# Lembrando que tenho 4 classes(tomate, batata, limão, cenoura)\n",
    "alexnet.classifier[6] = nn.Linear(4096, numero_classes)\n",
    "\n",
    "# Adicionando um novo modulo - 'LogSoftmax' converte efetivamente em probabilidade para facilitar nossa análise \n",
    "alexnet.classifier.add_module(\"7\", nn.LogSoftmax(dim=1))\n",
    "\n",
    "alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75c31ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos utilizar a função de erro de entropia cruzada (comum para problemas de classificação)\n",
    "\n",
    "funcao_erro = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af3e86a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
